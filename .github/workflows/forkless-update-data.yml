# Forkless update with data replication
# https://cryptousetech.atlassian.net/wiki/spaces/CI/pages/2586869792/Forkless+update+with+data

# Triger: only call from main workflow(re-usable workflows)
on:
  workflow_call:


# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:

  prepare-execution-matrix:

    name: execution matrix

    runs-on: self-hosted
    outputs:
      matrix: ${{ steps.create_matrix.outputs.matrix }}

    steps:

      - name: Clean Workspace
        uses: AutoModality/action-clean@v1.1.0

      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3.1.0
        with:
          ref: ${{ github.head_ref }}  #Checking out head commit

      - name: Read .env file
        uses: xom9ikk/dotenv@v2

      - name: Create Execution matrix
        uses: CertainLach/create-matrix-action@v4
        id: create_matrix
        with:
          matrix: |
            network {opal}, mainnet_branch {${{ env.OPAL_MAINNET_BRANCH }}}, relay_branch {${{ env.UNIQUEWEST_MAINNET_BRANCH }}}, fork_source {${{ env.OPAL_REPLICA_FROM }}}
            network {quartz}, mainnet_branch {${{ env.QUARTZ_MAINNET_BRANCH }}}, relay_branch {${{ env.KUSAMA_MAINNET_BRANCH }}}, fork_source {${{ env.QUARTZ_REPLICA_FROM }}}
            network {unique}, mainnet_branch {${{ env.UNIQUE_MAINNET_BRANCH }}}, relay_branch {${{ env.POLKADOT_MAINNET_BRANCH }}}, fork_source {${{ env.UNIQUE_REPLICA_FROM }}}

  forkless-data:

    needs: prepare-execution-matrix
    # The type of runner that the job will run on
    runs-on: [self-hosted,large]

    timeout-minutes: 1380

    name: ${{ matrix.network }}-data

    continue-on-error: true         #Do not stop testing of matrix runs failed.  As it decided during PR review - it required 50/50& Let's check it with false.

    strategy:
      matrix:
        include: ${{fromJson(needs.prepare-execution-matrix.outputs.matrix)}}

    steps:

      - name: Clean Workspace
        uses: AutoModality/action-clean@v1.1.0

      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3.1.0
        with:
          ref: ${{ github.head_ref }}  #Checking out head commit

      # Prepare SHA  
      - name: Prepare SHA
        uses: ./.github/actions/prepare

      - name: Read .env file
        uses: xom9ikk/dotenv@v2

      - name: Log in to Docker Hub
        uses: docker/login-action@v2.1.0
        with:
          username: ${{ secrets.CORE_DOCKERHUB_USERNAME }}
          password: ${{ secrets.CORE_DOCKERHUB_TOKEN }}

      - name: Check and pull polkadot image
        id: polkadot
        uses: cloudposse/github-action-docker-image-exists@main
        with:
          registry: registry.hub.docker.com
          organization: parity
          repository: polkadot
          login: ${{ secrets.CORE_DOCKERHUB_USERNAME }}
          password: ${{ secrets.CORE_DOCKERHUB_TOKEN }}
          tag: ${{ matrix.relay_branch }}

      - name: Prepare latest
        uses: ./.github/actions/buildContainer
        id: latest
        with:
          container: uniquenetwork/ci-data-${{ matrix.network }}
          tag: ${{ env.REF_SLUG }}-${{ env.BUILD_SHA }}
          context: .
          dockerfile: .docker/Dockerfile-unique
          args: |
            --build-arg NETWORK=${{ matrix.network }}
          dockerhub_username: ${{ secrets.CORE_DOCKERHUB_USERNAME }}
          dockerhub_token: ${{ secrets.CORE_DOCKERHUB_TOKEN }}

      - name: Extract wasms
        uses: ./.github/actions/extractDocker
        id: wasms
        with:
          image: ${{ steps.latest.outputs.name }}
          directory: /wasm

      - uses: actions/setup-node@v3.5.1
        with:
          node-version: 20

      - name: Install baedeker
        uses: UniqueNetwork/baedeker-action/setup@built

      - name: Setup library
        run: mkdir -p .baedeker/vendor/ && git clone https://github.com/UniqueNetwork/baedeker-library .baedeker/vendor/baedeker-library

      - name: Start network
        uses: UniqueNetwork/baedeker-action@built
        id: bdk
        with:
          jpath: |
            .baedeker/vendor
          tla-str: |
            relay_spec=${{ env.RELAY_CHAIN_TYPE }}-local
            forked_spec=${{ matrix.network }}
            fork_source=${{ matrix.fork_source }}
          inputs: |
            .baedeker/forkless-data.jsonnet
            snippet:(import 'baedeker-library/ops/rewrites.libsonnet').rewriteNodePaths({'bin/polkadot':{dockerImage:'${{ steps.polkadot.outputs.name }}'}})
            snippet:(import 'baedeker-library/ops/rewrites.libsonnet').rewriteNodePaths({'bin/unique':{dockerImage:'${{ steps.latest.outputs.name }}'}})

      - name: "Reconcile: runtime is upgraded"
        working-directory: js-packages/tests
        run: |
          yarn
          ../scripts/wait_for_first_block.sh
          echo "Executing upgrade"
          yarn node --no-warnings=ExperimentalWarning --loader ts-node/esm ../scripts/authorizeEnactUpgrade.ts ${{ steps.wasms.outputs.dir }}/${{ matrix.network }}-runtime/${{ matrix.network }}_runtime.compact.compressed.wasm
        env:
          RPC_URL: ${{ env.RELAY_UNIQUE_HTTP_URL }}

      - name: Run Parallel tests after forkless upgrade
        working-directory: js-packages/tests
        run: |
          yarn 
          yarn add mochawesome
          ../scripts/wait_for_first_block.sh
          echo "Ready to start tests"
          NOW=$(date +%s) && yarn testParallel --reporter mochawesome --reporter-options reportFilename=test-parallel-${NOW}
        env:
          RPC_URL: ${{ env.RELAY_UNIQUE_HTTP_URL }}

      - name: Run Sequential tests after forkless upgrade
        if: success() || failure()
        working-directory: js-packages/tests
        run: |
          yarn
          yarn add mochawesome
          NOW=$(date +%s) && yarn testSequential --reporter mochawesome --reporter-options reportFilename=test-sequential-${NOW}
        env:
          RPC_URL: ${{ env.RELAY_UNIQUE_HTTP_URL }}

      - name: Remove builder cache
        if: always()                   # run this step always
        run: |
          docker system prune -f
